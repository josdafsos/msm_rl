Initial topology:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 50)         │        11,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 50)         │         2,550 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 50)         │         2,550 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 50, 1)          │            51 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

Batch size is 32 until change is explicitly mentioned
1000 files (15000 samples), 50 epochs, no normalization
val_loss: 0.1042

1000 files (15000 samples), 50 epochs, [0 1] range input normalization
val_loss: 0.1598  - WTF?! looks like there is an overfit as training loss is higher than validation loss

permormance improved when the number of epochs is increase to 100, learning has not converged at this point
loss is in range 0.10 - 0.11

For 100 epochs with the normalization, validation loss is even better and in range 0.060 - 0.070.
BUT it is much lower than the training loss, which stays in range 0.0950 - 0.100

File size increased to 1500 (22500 samples)
With normalization the validation loss is around 0.12

Batch size increased to 64, validation loss is 0.12 - 0.13, training not converged. Potentially some extra variance in training loss, but not clear

File size increased to 2000 (30000 samples)
Epochs increased to 125
validation loss is 0.9 - 0.10

Relu activations change to elu (according to Matlab documentation, elu is also avilable in there)
initialization was He-Initialization, validation loss 0.11 - 0.12
switched back to relu
New topology:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 100)        │           600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 50)         │        30,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 40)         │        14,560 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 30)         │         1,230 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 50, 1)          │            31 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

Seems to perform much better with the same training parameters. validation loss 0.065 - 0.085

Run extra epochs. In total 250 epochs. After 200th epoch performance degrades. Best validation loss 0.05 - 0.06

File size increased to 2500 (37500 samples), 225 epochs
After 200th epoch val loss grows, validation loss 0.056 - 0.065
After 75 more epochs validation loss decreases insignificantly

Dropout 0.2 added to the model, validation loss 0.07 - 0.08, training not yet converged, but was close to it
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 100)        │           600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout (Dropout)               │ (None, 50, 100)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 50)         │        30,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_1 (Dropout)             │ (None, 50, 50)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 40)         │        14,560 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_2 (Dropout)             │ (None, 50, 40)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 30)         │         1,230 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 50, 1)          │            31 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

Learning rate adjustment added when no improvement is seen
# lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)

Previously trained model then was trained for 100 more epochs. Loss has stabilized at around 0.058 - 0.061

Dropout aws excluded, model returned to the initial topology. Initial learning rate is set to 0.01;
Modified learning rate decay: lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=5, min_lr=0.00005)

Num of files reduced to 2000 (30000 sequences)
After all the changes and 250 epochs, validation loss is 0.037 - 0.038. The result converged approximately at 200th epoch

Topology was changed to comprise only LSTM elements:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 100)        │        42,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 80)         │        57,920 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 1)          │            81 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 301,205 (1.15 MB)
 Trainable params: 100,401 (392.19 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 200,804 (784.39 KB)

Validation loss 0.056-0.060 almost converged after 200 epochs


"STABLE 1":

(this combination demonstrated the lowest loss so far)
New topology:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 75)         │           450 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 60)         │        32,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            61 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 235,355 (919.36 KB)
 Trainable params: 78,451 (306.45 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 156,904 (612.91 KB)

 Validation loss 0.0313 - 0.0330, after 200 epochs not fully converged
 Second try (225 epochs): validation loss 0.0315 - 0.0330, Almost converged

 Dense layer changed to 100 elements,  New params:
 Total params: 258,305 (1009.01 KB)
 Trainable params: 86,101 (336.33 KB)
 Non-trainable params: 0 (0.00 B)

 Validation loss 0.037 - 0.040, converged in ~230 epochs

New topology:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 100)        │           600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 75)         │        52,800 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 50, 50)         │        25,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            51 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 371,855 (1.42 MB)
 Trainable params: 123,951 (484.18 KB)
 Non-trainable params: 0 (0.00 B)

 Validation loss 0.0440 - 0.0460; almost converged after 250 epochs; files count - 2500

 For all the ongoing models minimum learning rate decreased from min_lr=0.00005 to min_lr=0.000025

 Model returned to "Stable_1" topology, but BatchNormalization layer is added before RELU activation
 New model:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 75)         │           450 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 50, 75)         │           300 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 50, 75)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 60)         │        32,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            61 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 235,955 (921.70 KB)
 Trainable params: 78,601 (307.04 KB)
 Non-trainable params: 150 (600.00 B)
 Optimizer params: 157,204 (614.08 KB)

 Converged after 150 epochs, validation loss 0.036 - 0.037

 With batch normalization initial learning rate increased to 0.015, learning rate decay changed from 0.8 to 0.7
 New model:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 125)         │           450 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 50, 80)         │           300 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 50, 80)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 80)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 60)         │        32,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            61 │
└─────────────────────────────────┴────────────────────────┴───────────────┘

2500 sample files. Converged after approximately 150 epochs. Validation loss 0.053

Same model, but batch size increased to 128, 3000 files, 45000 samples
validation loss 0.050 - 0.052 converged after 100 epochs. Even though validation loss is high, the approximation looks quite promising

Learning rate reduced from 0.015 to 0.012
Number of files increased to 3500
Batch size increased from 64 to 128
Second LSTM layer size increased from 60 to 80
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 125)        │           750 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 50, 125)        │           500 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 50, 125)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 80)         │        65,920 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 80)         │        51,520 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            81 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 355,815 (1.36 MB)
 Trainable params: 118,521 (462.97 KB)
 Non-trainable params: 250 (1000.00 B)
 Optimizer params: 237,044 (925.96 KB)

 Validation loss 0.0490 - 0.0500, convergence at around 100- 120 epochs. Good approximation

"STABLE 2":

 Batch size increased from 128 to 192, sample file increased to 4000
 Min learning rate reduced to min_lr=0.000020; Learning rate decay factor changed back to 0.8
 New model with extra LSTM layer:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 125)        │           750 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization             │ (None, 50, 125)        │           500 │
│ (BatchNormalization)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 50, 125)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 80)         │        65,920 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 80)         │        51,520 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 50, 40)         │        19,360 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            41 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
Trainable params: 137,841 (538.44 KB)

Not fully converged after 140 epochs; validation loss 0.0395 - 0.0420
Training continued with initial learning rate 0.0005 and 4500 file samples

Additional training with 100 more epochs. The model converged; validation loss is stably 0.0358 - 0.0362; good approximation

Model retrained with TensorFlow v2.10, model loss 0.0470 - 0.0480
Sample files reduced to 4000

No batch model is trained on 4500 samples, 300 epochs, almost converged



MODEL:  "4 LSTM"
New model in py 3.12 with 4 kHz frequency. Tested on all available data, 200 epochs. Converged, val loss around 0.0305 - 0.0310
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 100)        │           500 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 50, 100)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 50)         │        30,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 50)         │        20,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 50, 50)         │        20,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_3 (LSTM)                   │ (None, 50, 50)         │        20,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 50, 1)          │            51 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 91,351 (356.84 KB)
 Trainable params: 91,351 (356.84 KB)
 Non-trainable params: 0 (0.00 B)


New model LSTM_5_75: after 200 epochs not fully converged, val loss 0.063 - 0.065, trained on all the data

Model: "sequential"
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 50, 75)         │        24,000 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_3 (LSTM)                   │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_4 (LSTM)                   │ (None, 50, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 50, 1)          │            76 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 615,830 (2.35 MB)
 Trainable params: 205,276 (801.86 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 410,554 (1.57 MB)

 100 more epochs - not converged, val loss 0.042 - 0.043

 100 more epochs - still same val loss 0.042 - 0.043, On re-training, the model's validation starts from higher value and then again converges to the same loss


250 more epochs: validtaion loss converged 0.0347

 -----------
 sequence length reduced from 50 to 25
 -----------
 new model: LSTM_4_60

┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 60)         │        15,600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 60)         │        29,040 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 25, 60)         │        29,040 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_3 (LSTM)                   │ (None, 25, 60)         │        29,040 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 1)          │            61 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 308,345 (1.18 MB)
 Trainable params: 102,781 (401.49 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 205,564 (802.99 KB)

 250 epochs almost converged, 0.0474


 new model: LSTM_4_75_len_25, sequence length 25
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        24,000 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_2 (LSTM)                   │ (None, 25, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_3 (LSTM)                   │ (None, 25, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 1)          │            76 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 479,930 (1.83 MB)
 Trainable params: 159,976 (624.91 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 319,954 (1.22 MB)

 Fully converged, 300 epochs. Validation loss 0.0375

  new model: Relu255_LSTM75_double, sequence length 25
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 255)        │        19,380 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 255)        │        19,380 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           256 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 716,675 (2.73 MB)
 Trainable params: 238,891 (933.17 KB)

 trained for 300 epochs, almost converged, val loss 0.0177

new model: simple_Relu255_LSTM75_double, sequence length 25
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 128)        │         9,728 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        61,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 128)        │         9,728 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           129 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 544,082 (2.08 MB)
 Trainable params: 181,360 (708.44 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 362,722 (1.38 MB)

 Converged in 250 epochs, validation loss 0.0226

 new model:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 128)        │         9,728 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        61,200 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 1)          │            76 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 514,739 (1.96 MB)
 Trainable params: 171,579 (670.23 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 343,160 (1.31 MB)


converged after 300 epochs, validation loss 0.0240

New model:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 128)        │         9,728 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 1)          │           129 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 331,298 (1.26 MB)
 Trainable params: 110,432 (431.38 KB)

 Converged after 225 epochs. Validation loss 0.0475

 New model:
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │        99,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        45,300 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 1)          │            76 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 437,855 (1.67 MB)
 Trainable params: 145,951 (570.12 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 291,904 (1.11 MB)

 Converged after 250 epochs, validation loss 0.0413

 New model:
 ┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 255)        │         1,275 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 255)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 100)        │       142,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 160)        │        16,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 160)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 100)        │       104,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 160)        │        16,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 160)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           161 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 841,670 (3.21 MB)
 Trainable params: 280,556 (1.07 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 561,114 (2.14 MB)

 Converged after 300 epochs, validation loss 0.0161

 New model "LSTM_Relu_min_loss":
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 160)        │           800 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 160)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 100)        │       104,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 160)        │        16,160 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 160)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 100)        │       104,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 128)        │        12,928 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 128)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           129 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 716,453 (2.73 MB)
 Trainable params: 238,817 (932.88 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 477,636 (1.82 MB)

 Converged on 350 epochs, validation loss 0.0152; second validation loss re-training 0.0192 converged at around 320 epochs; 3rd val loss 0.0189, converged on 280 epoch; 177 converged on 300 epochs.

 New model "LSTM_Relu_param_opt"":
┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 150)        │           750 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 150)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 100)        │       100,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 120)        │        12,120 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 120)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        58,800 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 100)        │         7,600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 100)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           101 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 539,315 (2.06 MB)
 Trainable params: 179,771 (702.23 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 359,544 (1.37 MB)

 Converged after 300 epochs, validation loss 0.0200

 =================
 Minimum learning rate was decreased to 0.0000002 (10 times decrease)
 =================

 New model:
 ┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 300)        │         1,500 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 300)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 75)         │       112,800 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 150)        │        11,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 150)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 75)         │        67,800 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 150)        │        11,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 150)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │           151 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 615,155 (2.35 MB)
 Trainable params: 205,051 (800.98 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 410,104 (1.56 MB)

 Converged after 350 epochs, validation loss 0.0202

 New model:
 ┌─────────────────────────────────┬────────────────────────┬───────────────┐
│ Layer (type)                    │ Output Shape           │       Param # │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense (Dense)                   │ (None, 25, 120)        │           600 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation (Activation)         │ (None, 25, 120)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm (LSTM)                     │ (None, 25, 110)        │       101,640 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_1 (Dense)                 │ (None, 25, 120)        │        13,320 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_1 (Activation)       │ (None, 25, 120)        │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ lstm_1 (LSTM)                   │ (None, 25, 100)        │        88,400 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_2 (Dense)                 │ (None, 25, 70)         │         7,070 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ activation_2 (Activation)       │ (None, 25, 70)         │             0 │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_3 (Dense)                 │ (None, 25, 1)          │            71 │
└─────────────────────────────────┴────────────────────────┴───────────────┘
 Total params: 633,305 (2.42 MB)
 Trainable params: 211,101 (824.61 KB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 422,204 (1.61 MB)

 Converged after 300 epochs, validation loss 0.0273